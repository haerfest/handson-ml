{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "Build your own CNN and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "As per [Caffe2's MNIST tutorial](https://caffe2.ai/docs/tutorial-MNIST.html), we are going to build a small CNN based on the LeNet architecture:\n",
    "\n",
    "Layer  | Type            | Maps | Size    | Kernel size | Stride | Activation\n",
    "-------|-----------------|------|---------|-------------|--------|-----------\n",
    "logits | Fully Connected | -    | 10      | -           | -      | softmax\n",
    "F5     | Fully Connected | -    | 500     | -           | -      | relu\n",
    "S4     | Max Pooling     | 100  | 4 x 4   | 2 x 2       | 2      | -\n",
    "C3     | Convolution     | 100  | 8 x 8   | 5 x 5       | 1      | tanh\n",
    "S2     | Max Pooling     | 20   | 12 x 12 | 2 x 2       | 2      | -\n",
    "C1     | Convolution     | 20   | 28 x 28 | 5 x 5       | 1      | tanh\n",
    "X      | Input           | 1    | 28 x 28 | -           | -      | -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the data we will be feeding the network at each training step:\n",
    "\n",
    "- `X` is a batch of 28 x 28 grayscale (= 1 channel) images. The MNIST dataset contains them as a sequence of 768 pixel values, so we'll first reshape them to a 2D image.\n",
    "- `y` is a batch of class digits in the range 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28 * 28 * 1])\n",
    "y = tf.placeholder(tf.int32,   shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build the model according to the table above. This should be fairly straightforward, except perhaps for the last layer.\n",
    "\n",
    "The last layer of the network contains ten output neurons. Like every neuron in the network, they multiply their inputs by their weights and add a bias term:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\sum{Wx} + b\n",
    "\\end{equation}\n",
    "\n",
    "But note that they have no activation function. This means that they pass on the result of this calculation to their outputs as-is, and do not first perform a _tanh_ or _relu_ conversion. These output values are therefore not limited to a fixed range, such as [0, 1], but can take on any real number, both positive and negative.\n",
    "\n",
    "Now, we want to teach each output neuron to output a higher value when it thinks the input image contains \"its\" digit, and a lower value when it does not.\n",
    "\n",
    "We therefore treat these output values as [logits](https://stats.stackexchange.com/questions/52825/what-does-the-logit-value-actually-mean#52836), or _logarithmic odds_. Given a probability $p$, its odds is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{p}{1 - p}\n",
    "\\end{equation}\n",
    "\n",
    "And a logarithmic odd is simply the natural logarithm of this:\n",
    "\n",
    "\\begin{equation}\n",
    "\\ln \\frac{p}{1 - p}\n",
    "\\end{equation}\n",
    "\n",
    "The relationship can be shown graphically as well:\n",
    "\n",
    "![Curve](https://i.stack.imgur.com/h6N7o.png)\n",
    "\n",
    "The thing to take away is we want to teach an output neuron to output a higher _logit_ when it thinks the input image contains \"its\" digit, since a higher logit corresponds to a higher _probability_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('cnn'):\n",
    "\n",
    "    # Image: [768] --> [28 x 28 x 1].\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "    # Image: [28 x 28 x 1] --> [24 x 24 x 20].\n",
    "    c1 = tf.layers.conv2d(\n",
    "        X_reshaped,\n",
    "        filters=20,\n",
    "        kernel_size=[5, 5],\n",
    "        strides=[1, 1],\n",
    "        padding='valid',\n",
    "        activation=tf.nn.tanh)\n",
    "\n",
    "    # Image: [24 x 24 x 20] --> [12 x 12 x 20].\n",
    "    s2 = tf.layers.max_pooling2d(\n",
    "        c1,\n",
    "        pool_size=[2, 2],\n",
    "        strides=[2, 2],\n",
    "        padding='valid')\n",
    "\n",
    "    # Image: [12 x 12 x 20] --> [8 x 8 x 100].\n",
    "    c3 = tf.layers.conv2d(\n",
    "        s2,\n",
    "        filters=100,\n",
    "        kernel_size=[5, 5],\n",
    "        strides=[1, 1],\n",
    "        padding='valid',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Image: [8 x 8 x 100] --> [4 x 4 x 100].\n",
    "    s4 = tf.layers.max_pooling2d(\n",
    "        c3,\n",
    "        pool_size=[2, 2],\n",
    "        strides=[2, 2],\n",
    "        padding='valid')\n",
    "\n",
    "    # Image: [4 x 4 x 100] --> [1600].\n",
    "    s4_reshaped = tf.reshape(s4, [-1, 4 * 4 * 100])\n",
    "\n",
    "    # Image: [1600] --> [500].\n",
    "    f5 = tf.layers.dense(\n",
    "        s4_reshaped,\n",
    "        units=500,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Image: [500] --> [10]\n",
    "    logits = tf.layers.dense(\n",
    "        f5,\n",
    "        units=10,\n",
    "        activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn something, we must define a loss or cost function that we will aim to minimize while learning. For each image we feed the network, the loss tells us in essence how large the difference was between the answer given by the network and the desired answer, that is, the ground truth. Ideally we can minimize the loss to a value close to zero.\n",
    "\n",
    "Recall that when we feed the network a single image, we end up with ten $logits$ at the output end of the network. We also have one integer number in the range 0-9 that indicates the class of the digit visible in that image. How do we calculate a loss given this combination?\n",
    "\n",
    "**TODO:** Use one-hot ending and the non-sparse cross entropy function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=logits)\n",
    "\n",
    "    loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    \n",
    "    correct  = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    \n",
    "    optimizer   = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now         = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir      = '{}/run-{}/'.format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary      = tf.summary.scalar('loss', loss)\n",
    "acc_train_summary = tf.summary.scalar('acc_train', accuracy)\n",
    "acc_test_summary  = tf.summary.scalar('acc_test',  accuracy)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs   = 5\n",
    "batch_size = 100\n",
    "n_batches  = mnist.train.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Each epoch we train all batches.\n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "            # Evaluate the network now and then, so we can visualize\n",
    "            # its progress in Tensorboard.\n",
    "            if batch % 10 == 0:\n",
    "                step = epoch * n_batches + batch\n",
    "                file_writer.add_summary(\n",
    "                    loss_summary.eval(feed_dict={X: X_batch, y: y_batch}),\n",
    "                    step)\n",
    "                file_writer.add_summary(\n",
    "                    acc_train_summary.eval(feed_dict={X: X_batch, y: y_batch}),\n",
    "                    step)\n",
    "                file_writer.add_summary(\n",
    "                    acc_test_summary.eval(feed_dict={X: X_test,  y: y_test}),\n",
    "                    step)\n",
    "        \n",
    "        print(\"\\r{} of {} epochs\".format(epoch + 1, n_epochs), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
